[2025-09-15T23:42:20.364+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dds_to_clickhouse_enhanced.load_geo_analysis manual__2025-09-15T23:20:35.639977+00:00 [queued]>
[2025-09-15T23:42:20.392+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dds_to_clickhouse_enhanced.load_geo_analysis manual__2025-09-15T23:20:35.639977+00:00 [queued]>
[2025-09-15T23:42:20.393+0000] {taskinstance.py:1308} INFO - Starting attempt 3 of 3
[2025-09-15T23:42:20.456+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonOperator): load_geo_analysis> on 2025-09-15 23:20:35.639977+00:00
[2025-09-15T23:42:20.510+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'dds_to_clickhouse_enhanced', 'load_geo_analysis', 'manual__2025-09-15T23:20:35.639977+00:00', '--job-id', '609', '--raw', '--subdir', 'DAGS_FOLDER/dds_to_clickhouse.py', '--cfg-path', '/tmp/tmpgth_x0lb']
[2025-09-15T23:42:20.503+0000] {standard_task_runner.py:57} INFO - Started process 5010 to run task
[2025-09-15T23:42:20.516+0000] {standard_task_runner.py:85} INFO - Job 609: Subtask load_geo_analysis
[2025-09-15T23:42:20.673+0000] {logging_mixin.py:150} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-09-15T23:42:20.911+0000] {task_command.py:410} INFO - Running <TaskInstance: dds_to_clickhouse_enhanced.load_geo_analysis manual__2025-09-15T23:20:35.639977+00:00 [running]> on host 71d7292233fc
[2025-09-15T23:42:21.221+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dds_to_clickhouse_enhanced' AIRFLOW_CTX_TASK_ID='load_geo_analysis' AIRFLOW_CTX_EXECUTION_DATE='2025-09-15T23:20:35.639977+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-09-15T23:20:35.639977+00:00'
[2025-09-15T23:42:21.273+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dds_to_clickhouse.py", line 313, in load_geo_analysis
    ch_client.execute("INSERT INTO geo_analysis VALUES", df.to_dict("records"))
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/client.py", line 379, in execute
    columnar=columnar
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/client.py", line 608, in process_insert_query
    types_check=types_check, columnar=columnar)
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/client.py", line 660, in send_data
    self.connection.send_data(block)
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/connection.py", line 688, in send_data
    self.block_out.write(block)
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/streams/native.py", line 49, in write
    self.fout, types_check=block.types_check)
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/columns/service.py", line 167, in write_column
    column.write_data(items, buf)
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/columns/base.py", line 145, in write_data
    self._write_data(items, buf)
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/columns/base.py", line 149, in _write_data
    self.write_items(prepared, buf)
  File "/home/airflow/.local/lib/python3.7/site-packages/clickhouse_driver/columns/stringcolumn.py", line 18, in write_items
    buf.write_strings(items, encoding=self.encoding)
  File "clickhouse_driver/bufferedwriter.pyx", line 54, in clickhouse_driver.bufferedwriter.BufferedWriter.write_strings
AttributeError: 'int' object has no attribute 'encode'
[2025-09-15T23:42:21.301+0000] {taskinstance.py:1350} INFO - Marking task as FAILED. dag_id=dds_to_clickhouse_enhanced, task_id=load_geo_analysis, execution_date=20250915T232035, start_date=20250915T234220, end_date=20250915T234221
[2025-09-15T23:42:21.322+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 609 for task load_geo_analysis ('int' object has no attribute 'encode'; 5010)
[2025-09-15T23:42:21.350+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2025-09-15T23:42:21.381+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
